{% load_yaml as lookup_map %}
default:
  worker_service: 'spark-worker'
  master_service: 'spark-master'
  user: spark
  prefix: /usr/local/lib
  config_dir: /etc/spark
  log_dir: /var/log/spark
  work_dir: /tmp/spark
  pid_dir: /var/run/spark
  niceness: 0

  version: "2.1.0"
  hadoop_version: "2.7"
  with_hadoop: true
  archive_url: "http://apache.cs.utah.edu/spark/spark-%(version)s"
  archive_type: "tgz"
  # used for minion targeting and master discovery
  worker_role: 'spark-worker'
  master_role: 'spark-master'
  
  master_host: ~
  master_port: 7077
  master_ui_port: 8080
  master_opts: []
  local_dirs: /tmp/spark/scratch
  
  worker_cores: 0 # all cores
  worker_memory: 2g
  worker_instances: 1
  worker_webui_port: 8081
  worker_dir: ~
  worker_opts: []
  daemon_memory: 1g
  daemon_java_opts: []
  public_dns: ~

  init_system: ~
  init_scripts: ~
  init_overrides: ~
  
Debian:
  init_system: systemd
  init_scripts: /etc/systemd/system
  init_overrides: /etc/default
  java_deps:
    - default-jre
    - default-jdk
RedHat:
  init_system: systemd
  init_scripts: /usr/lib/systemd/system
  init_overrides: /etc/systemd/system
  java_deps:
    - java-1.8.0-openjdk
    - java-1.8.0-openjdk-devel
{% endload %}

{% load_yaml as versions %}
with_hadoop:
  "2.1.0":
    name: "spark-%(version)s-bin-hadoop%(hadoop_version)s"
    hash: "sha256=0834c775f38473f67cb122e0ec21074f800ced50c1ff1b9e37e222a0069dc5c7"
without_hadoop:
  "2.1.0":
    name: "spark-%(version)s-bin-without-hadoop"
    hash: "sha256=3ca4ecb0eb9a00de5099cc2564ed957433a2d15d9d645a60470324621853c5ae"
{% endload %}

