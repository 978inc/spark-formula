{% load_yaml as lookup_map %}
default:
  service: spark-worker
  user: spark
  prefix: /usr/local
  config_dir: /etc/spark
  log_dir: /var/log/spark
  version: "2.1.0"
  hadoop_version: "2.7"
  with_hadoop: true
  archive_url: "http://apache.cs.utah.edu/spark/spark-%(version)s"
  archive_type: "tgz"
  # used for minion targeting and master discovery
  worker_role: 'spark-worker'
  master_role: 'spark-master'
  master_port: 7077
  master_ui_port: 8080
  master_opts: []
  local_dirs: /tmp/spark/scratch
  
  worker_cores: 0 # all cores
  worker_memory: 2g
  worker_instances: 1
  worker_webui_port: 8081
  worker_dir: SPARK_HOME/work
  worker_opts: []
  daemon_memory: 1g
  daemon_java_opts: []
  public_dns: ~
Debian: {}
RedHat: {}
{% endload %}

{% load_yaml as versions %}
with_hadoop:
  "2.1.0":
    name: "spark-%(version)s-bin-hadoop%(hadoop_version)s"
    hash: "sha256=0834c775f38473f67cb122e0ec21074f800ced50c1ff1b9e37e222a0069dc5c7"
without_hadoop:
  "2.1.0":
    name: "spark-%(version)s-bin-without-hadoop"
    hash: "sha256=3ca4ecb0eb9a00de5099cc2564ed957433a2d15d9d645a60470324621853c5ae"
{% endload %}

